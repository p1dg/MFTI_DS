{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table https://colab.research.google.com/drive/1LO7mJBnkccfwlKUFX17rJONbf_tUEukC?usp=sharing\n",
    "# game Pong 18.9 (1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import deque\n",
    "from utils import DQNbn, make_env, ReplayMemory, train\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"PongNoFrameskip-v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.reset()[0])\n",
    "plt.axis('off')  # Убрать оси координат\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action_space: 6 \n",
      "State_space: (210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape\n",
    "\n",
    "print(f'Action_space: {n_actions} \\nState_space: {env.observation_space.shape}')\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 1\n",
    "EPS_END = 0.02\n",
    "EPS_DECAY = 1000000\n",
    "TARGET_UPDATE = 1000\n",
    "RENDER = False\n",
    "lr = 1e-4\n",
    "INITIAL_MEMORY = 1000\n",
    "MEMORY_SIZE = 10 * INITIAL_MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = DQNbn(n_actions=6).to(device)\n",
    "target_net = DQNbn(n_actions=6).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr=lr)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "# create environment\n",
    "env = gym.make(\"PongNoFrameskip-v4\")\n",
    "env = make_env(env)\n",
    "\n",
    "memory = ReplayMemory(MEMORY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/400 [00:02<14:42,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 820 \t Episode: 0/819 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/400 [00:07<07:04,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 5701 \t Episode: 5/962 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 11/400 [00:11<06:27,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 10114 \t Episode: 10/841 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 16/400 [00:16<06:18,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 14535 \t Episode: 15/949 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 21/400 [00:21<06:08,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 19121 \t Episode: 20/760 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 26/400 [00:26<05:42,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 23620 \t Episode: 25/954 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 31/400 [00:31<05:58,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 27919 \t Episode: 30/815 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 36/400 [00:37<06:57,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 32695 \t Episode: 35/905 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 41/400 [00:43<06:59,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 37432 \t Episode: 40/1023 \t Total reward: -18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 46/400 [00:48<06:54,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 41864 \t Episode: 45/1027 \t Total reward: -19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 51/400 [00:54<07:15,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 46786 \t Episode: 50/996 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 56/400 [01:00<06:30,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 51229 \t Episode: 55/946 \t Total reward: -19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 61/400 [01:06<06:30,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 55767 \t Episode: 60/841 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 66/400 [01:12<06:24,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 60533 \t Episode: 65/757 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 71/400 [01:17<06:08,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 65011 \t Episode: 70/905 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 76/400 [01:23<06:15,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 69460 \t Episode: 75/837 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 81/400 [01:29<06:35,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 74418 \t Episode: 80/926 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 86/400 [01:35<06:01,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 78844 \t Episode: 85/838 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 91/400 [01:41<05:55,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 83319 \t Episode: 90/780 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 96/400 [01:46<05:19,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 88032 \t Episode: 95/803 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 101/400 [01:51<05:20,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 92434 \t Episode: 100/1001 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 106/400 [01:57<05:04,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 96909 \t Episode: 105/869 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 111/400 [02:01<04:23,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 101312 \t Episode: 110/803 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 116/400 [02:07<04:52,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 106180 \t Episode: 115/1092 \t Total reward: -19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 121/400 [02:11<04:26,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 110704 \t Episode: 120/759 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 126/400 [02:17<04:45,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 115298 \t Episode: 125/959 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 131/400 [02:22<04:19,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 119597 \t Episode: 130/833 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 136/400 [02:27<04:21,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 124088 \t Episode: 135/911 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 141/400 [02:31<03:59,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 128389 \t Episode: 140/834 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 146/400 [02:37<04:27,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 132758 \t Episode: 145/880 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 151/400 [02:43<04:52,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 137501 \t Episode: 150/991 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 156/400 [02:48<04:26,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 141632 \t Episode: 155/895 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 161/400 [02:53<03:52,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 145742 \t Episode: 160/757 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 166/400 [02:58<03:49,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 150198 \t Episode: 165/1025 \t Total reward: -18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 171/400 [03:03<04:26,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 154895 \t Episode: 170/899 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 176/400 [03:08<03:34,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 159224 \t Episode: 175/785 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 181/400 [03:14<04:05,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 163589 \t Episode: 180/1022 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 186/400 [03:19<03:57,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 167996 \t Episode: 185/876 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 191/400 [03:25<04:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 172473 \t Episode: 190/864 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 196/400 [03:31<03:55,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 177111 \t Episode: 195/833 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 201/400 [03:36<03:30,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 181129 \t Episode: 200/757 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 206/400 [03:42<03:30,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 185378 \t Episode: 205/761 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 211/400 [03:48<03:22,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 189552 \t Episode: 210/817 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 216/400 [03:54<03:41,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 194075 \t Episode: 215/879 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 221/400 [03:59<03:24,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 198157 \t Episode: 220/837 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 226/400 [04:05<03:11,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 202444 \t Episode: 225/914 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 231/400 [04:11<03:19,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 206940 \t Episode: 230/1103 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 236/400 [04:17<03:25,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 211385 \t Episode: 235/948 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 241/400 [04:22<03:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 216067 \t Episode: 240/972 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 246/400 [04:28<02:59,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 220968 \t Episode: 245/939 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 251/400 [04:34<02:57,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 225934 \t Episode: 250/876 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 256/400 [04:40<02:43,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 230678 \t Episode: 255/903 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 261/400 [04:46<02:32,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 234739 \t Episode: 260/821 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 266/400 [04:52<02:33,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 239293 \t Episode: 265/847 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 271/400 [04:58<02:36,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 243762 \t Episode: 270/928 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 276/400 [05:04<02:30,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 248331 \t Episode: 275/818 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 281/400 [05:10<02:22,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 252706 \t Episode: 280/1124 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 286/400 [05:15<01:57,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 256740 \t Episode: 285/759 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 291/400 [05:20<02:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 261224 \t Episode: 290/1036 \t Total reward: -18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 296/400 [05:26<02:07,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 265901 \t Episode: 295/1018 \t Total reward: -20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 301/400 [05:31<01:32,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 270054 \t Episode: 300/754 \t Total reward: -21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 306/400 [05:38<01:43,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 275261 \t Episode: 305/1145 \t Total reward: -19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINITIAL_MEMORY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy_net\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_net\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGAMMA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_update\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTARGET_UPDATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPS_END\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPS_START\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPS_DECAY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# torch.save(policy_net, \"dqn_pong_model\")\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# policy_net = torch.load(\"dqn_pong_model\")\u001b[39;00m\n",
      "File \u001b[0;32m~/MFTI_DS/rl/hw_2_atari_games/utils.py:367\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(env, n_episodes, memory, device, initial_memory, policy_net, target_net, gamma, optimizer, batch_size, target_update, eps_end, eps_start, eps_decay, render)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m     next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreward\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m memory\u001b[38;5;241m.\u001b[39mpush(state, action\u001b[38;5;241m.\u001b[39mto(device), next_state, reward\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m    370\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\n",
    "    env=env, \n",
    "    n_episodes=400,\n",
    "    memory=memory, \n",
    "    device=device, \n",
    "    initial_memory=INITIAL_MEMORY, \n",
    "    policy_net=policy_net, \n",
    "    target_net=target_net, \n",
    "    gamma=GAMMA, \n",
    "    optimizer=optimizer, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    target_update=TARGET_UPDATE, \n",
    "    eps_end=EPS_END, \n",
    "    eps_start=EPS_START, \n",
    "    eps_decay=EPS_DECAY,\n",
    "    render=False,\n",
    ")\n",
    "# torch.save(policy_net, \"dqn_pong_model\")\n",
    "# policy_net = torch.load(\"dqn_pong_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
