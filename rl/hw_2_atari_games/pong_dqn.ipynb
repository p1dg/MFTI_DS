{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table https://colab.research.google.com/drive/1LO7mJBnkccfwlKUFX17rJONbf_tUEukC?usp=sharing\n",
    "# game Pong 18.9 (1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import deque\n",
    "from utils import DQNbn, DQN, make_env, ReplayMemory, train\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"PongNoFrameskip-v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.reset()[0])\n",
    "plt.axis(\"off\")  # Убрать оси координат\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action_space: 6 \n",
      "State_space: (210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape\n",
    "\n",
    "print(f\"Action_space: {n_actions} \\nState_space: {env.observation_space.shape}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "EPS_START = 1\n",
    "EPS_END = 0.02\n",
    "EPS_DECAY = 100000\n",
    "TARGET_UPDATE = 1000\n",
    "RENDER = False\n",
    "lr = 1e-4\n",
    "INITIAL_MEMORY = 10000\n",
    "MEMORY_SIZE = 10 * INITIAL_MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = DQNbn(n_actions=4).to(device)  # убираем действия с FIRE\n",
    "target_net = DQNbn(n_actions=4).to(device)\n",
    "# policy_net = DQN(n_actions=4, in_channels=4).to(device)  # убираем действия с FIRE\n",
    "# target_net = DQN(n_actions=4, in_channels=4).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr=lr)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "# create environment\n",
    "env = gym.make(\"PongNoFrameskip-v4\")\n",
    "env = make_env(env)\n",
    "\n",
    "memory = ReplayMemory(MEMORY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/home/p1dg/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/p1dg/.local/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  0%|          | 1/1000 [00:04<1:15:20,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 785 \t Episode: 0/784 \t Total reward episode: -21.0 Total loss: 0.0 \t Avg_10 loss: nan \t Avg_10 total_reward: nan  \t eps_threshold: 0.9923371161694993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:05<43:37,  2.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 1821 \t Episode: 1/1035 \t Total reward episode: -20.0 Total loss: 0.0 \t Avg_10 loss: nan \t Avg_10 total_reward: nan  \t eps_threshold: 0.9823157041927075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:07<32:59,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 2761 \t Episode: 2/939 \t Total reward episode: -20.0 Total loss: 0.0 \t Avg_10 loss: nan \t Avg_10 total_reward: nan  \t eps_threshold: 0.9733123187795681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:08<29:04,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 3820 \t Episode: 3/1058 \t Total reward episode: -21.0 Total loss: 0.0 \t Avg_10 loss: nan \t Avg_10 total_reward: nan  \t eps_threshold: 0.9632700092048767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:09<26:33,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 4823 \t Episode: 4/1002 \t Total reward episode: -21.0 Total loss: 0.0 \t Avg_10 loss: nan \t Avg_10 total_reward: nan  \t eps_threshold: 0.9538562996846341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [00:11<24:50,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 5817 \t Episode: 5/993 \t Total reward episode: -19.0 Total loss: 0.0 \t Avg_10 loss: nan \t Avg_10 total_reward: nan  \t eps_threshold: 0.9446197497690892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [00:12<23:03,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 6694 \t Episode: 6/876 \t Total reward episode: -21.0 Total loss: 0.0 \t Avg_10 loss: nan \t Avg_10 total_reward: nan  \t eps_threshold: 0.9365462884375969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [00:13<21:55,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 7594 \t Episode: 7/899 \t Total reward episode: -21.0 Total loss: 0.0 \t Avg_10 loss: nan \t Avg_10 total_reward: nan  \t eps_threshold: 0.9283343808560768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [00:14<20:32,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 8414 \t Episode: 8/819 \t Total reward episode: -21.0 Total loss: 0.0 \t Avg_10 loss: nan \t Avg_10 total_reward: nan  \t eps_threshold: 0.9209164938346917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [00:15<19:58,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 9252 \t Episode: 9/837 \t Total reward episode: -20.0 Total loss: 0.0 \t Avg_10 loss: nan \t Avg_10 total_reward: nan  \t eps_threshold: 0.9133983585993197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p1dg/MFTI_DS/rl/hw_2_atari_games/utils.py:390: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  next_state_values[non_final_mask] = (\n",
      "  1%|          | 11/1000 [00:18<27:57,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 10098 \t Episode: 10/845 \t Total reward episode: -21.0 Total loss: 1.5384291397640482 \t Avg_10 loss: 1.5384291397640482 \t Avg_10 total_reward: -21.0  \t eps_threshold: 0.9058720894927634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [00:30<1:19:35,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 11053 \t Episode: 11/954 \t Total reward episode: -20.0 Total loss: 5.066880816681078 \t Avg_10 loss: 3.302654978222563 \t Avg_10 total_reward: -20.5  \t eps_threshold: 0.8974522796224502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 13/1000 [00:41<1:50:29,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 11898 \t Episode: 12/844 \t Total reward episode: -21.0 Total loss: 1.9002340498554986 \t Avg_10 loss: 2.8351813354335413 \t Avg_10 total_reward: -20.666666666666668  \t eps_threshold: 0.8900690459536175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 14/1000 [00:54<2:19:23,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 12869 \t Episode: 13/970 \t Total reward episode: -20.0 Total loss: 2.0752172843785957 \t Avg_10 loss: 2.645190322669805 \t Avg_10 total_reward: -20.5  \t eps_threshold: 0.8816615599196866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 15/1000 [01:04<2:29:23,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 13673 \t Episode: 14/803 \t Total reward episode: -21.0 Total loss: 1.5697403311933158 \t Avg_10 loss: 2.430100324374507 \t Avg_10 total_reward: -20.6  \t eps_threshold: 0.8747615760817538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/1000 [01:15<2:36:38,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 14490 \t Episode: 15/816 \t Total reward episode: -21.0 Total loss: 1.7281581927090883 \t Avg_10 loss: 2.3131099690969372 \t Avg_10 total_reward: -20.666666666666668  \t eps_threshold: 0.8678066236720018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 17/1000 [01:27<2:48:47, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 15431 \t Episode: 16/940 \t Total reward episode: -21.0 Total loss: 1.7731696577684488 \t Avg_10 loss: 2.2359756389071532 \t Avg_10 total_reward: -20.714285714285715  \t eps_threshold: 0.8598661817151562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 18/1000 [01:38<2:54:11, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 16283 \t Episode: 17/851 \t Total reward episode: -21.0 Total loss: 1.7360161568358308 \t Avg_10 loss: 2.173480703648238 \t Avg_10 total_reward: -20.75  \t eps_threshold: 0.852740918570031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1000 [01:51<3:02:46, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 17248 \t Episode: 18/964 \t Total reward episode: -21.0 Total loss: 1.8761331008281559 \t Avg_10 loss: 2.140442081112673 \t Avg_10 total_reward: -20.77777777777778  \t eps_threshold: 0.844743617742945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1000 [02:01<2:58:26, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 18065 \t Episode: 19/816 \t Total reward episode: -21.0 Total loss: 1.4759411009581527 \t Avg_10 loss: 2.0739919830972213 \t Avg_10 total_reward: -20.8  \t eps_threshold: 0.8380329129427329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1000 [02:15<3:11:16, 11.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 19123 \t Episode: 20/1057 \t Total reward episode: -20.0 Total loss: 2.2085922729456797 \t Avg_10 loss: 2.1410082964153845 \t Avg_10 total_reward: -20.7  \t eps_threshold: 0.8294237475153419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/1000 [02:29<3:24:32, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 20229 \t Episode: 21/1105 \t Total reward episode: -19.0 Total loss: 2.368584072464728 \t Avg_10 loss: 1.8711786219937494 \t Avg_10 total_reward: -20.6  \t eps_threshold: 0.8205208446732809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 23/1000 [02:39<3:14:03, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 21032 \t Episode: 22/802 \t Total reward episode: -21.0 Total loss: 1.6483720299438573 \t Avg_10 loss: 1.8459924200025852 \t Avg_10 total_reward: -20.6  \t eps_threshold: 0.8141184024987843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 24/1000 [02:54<3:24:26, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 22121 \t Episode: 23/1088 \t Total reward episode: -21.0 Total loss: 2.3383416136784945 \t Avg_10 loss: 1.8723048529325752 \t Avg_10 total_reward: -20.7  \t eps_threshold: 0.8055173707146707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 25/1000 [03:07<3:29:35, 12.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 23142 \t Episode: 24/1020 \t Total reward episode: -20.0 Total loss: 2.282000456325477 \t Avg_10 loss: 1.9435308654457912 \t Avg_10 total_reward: -20.6  \t eps_threshold: 0.7975380421483783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1000 [03:23<3:42:37, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 24264 \t Episode: 25/1121 \t Total reward episode: -19.0 Total loss: 2.59927889413666 \t Avg_10 loss: 2.0306429355885482 \t Avg_10 total_reward: -20.4  \t eps_threshold: 0.7888628242965392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 27/1000 [03:34<3:30:51, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 25153 \t Episode: 26/888 \t Total reward episode: -20.0 Total loss: 2.0753255735035054 \t Avg_10 loss: 2.060858527162054 \t Avg_10 total_reward: -20.3  \t eps_threshold: 0.7820579263768515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28/1000 [03:47<3:27:37, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 26118 \t Episode: 27/964 \t Total reward episode: -21.0 Total loss: 2.334031665319344 \t Avg_10 loss: 2.1206600780104052 \t Avg_10 total_reward: -20.3  \t eps_threshold: 0.7747394358968036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 29/1000 [04:00<3:31:32, 13.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 27124 \t Episode: 28/1005 \t Total reward episode: -20.0 Total loss: 2.7325794979406055 \t Avg_10 loss: 2.2063047177216504 \t Avg_10 total_reward: -20.2  \t eps_threshold: 0.7671848205993758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 30/1000 [04:14<3:34:31, 13.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 28122 \t Episode: 29/997 \t Total reward episode: -21.0 Total loss: 2.7537946295924485 \t Avg_10 loss: 2.33409007058508 \t Avg_10 total_reward: -20.2  \t eps_threshold: 0.7597650025664133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 31/1000 [04:29<3:41:53, 13.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 29195 \t Episode: 30/1072 \t Total reward episode: -19.0 Total loss: 3.762686902686255 \t Avg_10 loss: 2.4894995335591377 \t Avg_10 total_reward: -20.1  \t eps_threshold: 0.7518697578269594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/1000 [04:44<3:49:14, 14.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 30271 \t Episode: 31/1075 \t Total reward episode: -20.0 Total loss: 7.6909314970253035 \t Avg_10 loss: 3.021734276015195 \t Avg_10 total_reward: -20.2  \t eps_threshold: 0.744037054746134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1000 [05:00<3:55:07, 14.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 31362 \t Episode: 32/1090 \t Total reward episode: -20.0 Total loss: 6.9155314092640765 \t Avg_10 loss: 3.548450213947217 \t Avg_10 total_reward: -20.1  \t eps_threshold: 0.7361807445774751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 34/1000 [05:20<4:23:35, 16.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 32866 \t Episode: 33/1503 \t Total reward episode: -18.0 Total loss: 7.217482102278154 \t Avg_10 loss: 4.036364262807183 \t Avg_10 total_reward: -19.8  \t eps_threshold: 0.7254899822333933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 35/1000 [05:39<4:33:30, 17.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 34142 \t Episode: 34/1275 \t Total reward episode: -20.0 Total loss: 6.448888847604394 \t Avg_10 loss: 4.453053101935074 \t Avg_10 total_reward: -19.8  \t eps_threshold: 0.716545119648148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 36/1000 [05:55<4:32:35, 16.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 35288 \t Episode: 35/1145 \t Total reward episode: -21.0 Total loss: 4.008131194743328 \t Avg_10 loss: 4.593938331995742 \t Avg_10 total_reward: -20.0  \t eps_threshold: 0.7086082775452208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 37/1000 [06:21<5:14:58, 19.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 37085 \t Episode: 36/1796 \t Total reward episode: -19.0 Total loss: 6.224507595296018 \t Avg_10 loss: 5.008856534174993 \t Avg_10 total_reward: -19.9  \t eps_threshold: 0.6963445067951373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 38/1000 [06:36<4:53:13, 18.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 38171 \t Episode: 37/1085 \t Total reward episode: -21.0 Total loss: 3.9991635887417942 \t Avg_10 loss: 5.175369726517237 \t Avg_10 total_reward: -19.9  \t eps_threshold: 0.6890391453630609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 39/1000 [06:58<5:09:08, 19.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 39737 \t Episode: 38/1565 \t Total reward episode: -16.0 Total loss: 5.513590523740277 \t Avg_10 loss: 5.4534708290972045 \t Avg_10 total_reward: -19.5  \t eps_threshold: 0.6786436018975865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 40/1000 [07:18<5:09:31, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 41219 \t Episode: 39/1481 \t Total reward episode: -19.0 Total loss: 4.859774122654926 \t Avg_10 loss: 5.664068778403452 \t Avg_10 total_reward: -19.3  \t eps_threshold: 0.668954477465991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 41/1000 [07:34<4:57:07, 18.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 42491 \t Episode: 40/1271 \t Total reward episode: -20.0 Total loss: 3.9514038378256373 \t Avg_10 loss: 5.682940471917391 \t Avg_10 total_reward: -19.4  \t eps_threshold: 0.6607520545171889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 42/1000 [07:51<4:49:03, 18.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 43735 \t Episode: 41/1243 \t Total reward episode: -21.0 Total loss: 4.122604639851488 \t Avg_10 loss: 5.3261077862000095 \t Avg_10 total_reward: -19.5  \t eps_threshold: 0.65283047335135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 43/1000 [08:08<4:42:07, 17.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 44939 \t Episode: 42/1203 \t Total reward episode: -18.0 Total loss: 4.114051876356825 \t Avg_10 loss: 5.0459598329092845 \t Avg_10 total_reward: -19.3  \t eps_threshold: 0.6452568789801233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 44/1000 [08:29<4:55:32, 18.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 46404 \t Episode: 43/1464 \t Total reward episode: -17.0 Total loss: 5.14010114048142 \t Avg_10 loss: 4.8382217367296105 \t Avg_10 total_reward: -19.2  \t eps_threshold: 0.6361636363393653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 45/1000 [08:48<4:59:35, 18.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 47849 \t Episode: 44/1444 \t Total reward episode: -20.0 Total loss: 4.634845994121861 \t Avg_10 loss: 4.656817451381357 \t Avg_10 total_reward: -19.2  \t eps_threshold: 0.627324091316442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 46/1000 [09:10<5:15:01, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 49446 \t Episode: 45/1596 \t Total reward episode: -21.0 Total loss: 5.945758123125415 \t Avg_10 loss: 4.850580144219566 \t Avg_10 total_reward: -19.2  \t eps_threshold: 0.6177021611881336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 47/1000 [09:38<5:53:09, 22.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 51439 \t Episode: 46/1992 \t Total reward episode: -20.0 Total loss: 8.031551562715322 \t Avg_10 loss: 5.031284540961496 \t Avg_10 total_reward: -19.3  \t eps_threshold: 0.6059078775451763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 48/1000 [10:01<5:54:11, 22.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 52988 \t Episode: 47/1548 \t Total reward episode: -18.0 Total loss: 6.19766280654585 \t Avg_10 loss: 5.251134462741902 \t Avg_10 total_reward: -19.0  \t eps_threshold: 0.596902094382585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 49/1000 [10:23<5:55:54, 22.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 54597 \t Episode: 48/1608 \t Total reward episode: -19.0 Total loss: 7.48574774939334 \t Avg_10 loss: 5.448350185307208 \t Avg_10 total_reward: -19.3  \t eps_threshold: 0.5876940173182262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 50/1000 [10:46<5:55:12, 22.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 56129 \t Episode: 49/1531 \t Total reward episode: -19.0 Total loss: 7.253083486924879 \t Avg_10 loss: 5.687681121734204 \t Avg_10 total_reward: -19.3  \t eps_threshold: 0.5790632256421163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [11:05<5:41:13, 21.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 57542 \t Episode: 50/1412 \t Total reward episode: -17.0 Total loss: 6.722470864304341 \t Avg_10 loss: 5.964787824382074 \t Avg_10 total_reward: -19.0  \t eps_threshold: 0.5712192107379651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 52/1000 [11:32<6:03:10, 22.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 59453 \t Episode: 51/1910 \t Total reward episode: -17.0 Total loss: 7.969056376838125 \t Avg_10 loss: 6.349432998080738 \t Avg_10 total_reward: -18.6  \t eps_threshold: 0.56078542397935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 53/1000 [11:54<5:58:55, 22.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 61056 \t Episode: 52/1602 \t Total reward episode: -19.0 Total loss: 7.028816606500186 \t Avg_10 loss: 6.640909471095074 \t Avg_10 total_reward: -18.7  \t eps_threshold: 0.5521857442139464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 54/1000 [12:17<6:03:01, 23.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 62796 \t Episode: 53/1739 \t Total reward episode: -16.0 Total loss: 8.13565940852277 \t Avg_10 loss: 6.940465297899209 \t Avg_10 total_reward: -18.6  \t eps_threshold: 0.543005809306904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 55/1000 [12:42<6:07:40, 23.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 64557 \t Episode: 54/1760 \t Total reward episode: -20.0 Total loss: 8.915421929617878 \t Avg_10 loss: 7.36852289144881 \t Avg_10 total_reward: -18.6  \t eps_threshold: 0.5338762982793738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 56/1000 [13:05<6:05:53, 23.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 66209 \t Episode: 55/1651 \t Total reward episode: -17.0 Total loss: 9.586749922658782 \t Avg_10 loss: 7.732622071402147 \t Avg_10 total_reward: -18.2  \t eps_threshold: 0.5254567983808466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 57/1000 [13:30<6:16:39, 23.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 68009 \t Episode: 56/1799 \t Total reward episode: -18.0 Total loss: 9.898871286888607 \t Avg_10 loss: 7.919354043819476 \t Avg_10 total_reward: -18.0  \t eps_threshold: 0.5164399709102536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 58/1000 [13:51<5:59:26, 22.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 69492 \t Episode: 57/1482 \t Total reward episode: -20.0 Total loss: 8.363980277616065 \t Avg_10 loss: 8.135985790926497 \t Avg_10 total_reward: -18.2  \t eps_threshold: 0.5091320880272945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 59/1000 [14:11<5:45:41, 22.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 70969 \t Episode: 58/1476 \t Total reward episode: -19.0 Total loss: 7.7875330375973135 \t Avg_10 loss: 8.166164319746894 \t Avg_10 total_reward: -18.2  \t eps_threshold: 0.5019606981723604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 60/1000 [14:40<6:18:57, 24.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 73105 \t Episode: 59/2135 \t Total reward episode: -18.0 Total loss: 10.79504028201336 \t Avg_10 loss: 8.520359999255742 \t Avg_10 total_reward: -18.1  \t eps_threshold: 0.4917751861857849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 61/1000 [15:08<6:35:30, 25.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 75139 \t Episode: 60/2033 \t Total reward episode: -18.0 Total loss: 10.410384112561587 \t Avg_10 loss: 8.889151324081467 \t Avg_10 total_reward: -18.2  \t eps_threshold: 0.4822762109640326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1000 [15:42<7:17:10, 27.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 77652 \t Episode: 61/2512 \t Total reward episode: -17.0 Total loss: 12.169285230629612 \t Avg_10 loss: 9.309174209460616 \t Avg_10 total_reward: -18.2  \t eps_threshold: 0.470803962323561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 63/1000 [16:09<7:13:16, 27.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 79639 \t Episode: 62/1986 \t Total reward episode: -17.0 Total loss: 9.445464634161908 \t Avg_10 loss: 9.550839012226788 \t Avg_10 total_reward: -18.0  \t eps_threshold: 0.46193489359296197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 64/1000 [16:40<7:27:50, 28.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 81823 \t Episode: 63/2183 \t Total reward episode: -16.0 Total loss: 9.31834005418932 \t Avg_10 loss: 9.669107076793443 \t Avg_10 total_reward: -18.0  \t eps_threshold: 0.45238767067875224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 65/1000 [17:11<7:36:03, 29.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 84041 \t Episode: 64/2217 \t Total reward episode: -19.0 Total loss: 8.646660858707037 \t Avg_10 loss: 9.642230969702359 \t Avg_10 total_reward: -17.9  \t eps_threshold: 0.44290288722688914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 66/1000 [17:38<7:26:43, 28.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 86013 \t Episode: 65/1971 \t Total reward episode: -19.0 Total loss: 7.468080704507884 \t Avg_10 loss: 9.43036404788727 \t Avg_10 total_reward: -18.1  \t eps_threshold: 0.43464493332615994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 67/1000 [18:02<7:04:00, 27.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 87736 \t Episode: 66/1722 \t Total reward episode: -20.0 Total loss: 6.325375593616627 \t Avg_10 loss: 9.073014478560072 \t Avg_10 total_reward: -18.3  \t eps_threshold: 0.42756179757119983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 68/1000 [18:35<7:30:55, 29.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 90188 \t Episode: 67/2451 \t Total reward episode: -17.0 Total loss: 9.615702562383376 \t Avg_10 loss: 9.198186707036802 \t Avg_10 total_reward: -18.0  \t eps_threshold: 0.4176899062837444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 69/1000 [19:01<7:17:50, 28.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 92104 \t Episode: 68/1915 \t Total reward episode: -19.0 Total loss: 7.555084344756324 \t Avg_10 loss: 9.174941837752703 \t Avg_10 total_reward: -18.0  \t eps_threshold: 0.4101427007916661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 70/1000 [19:28<7:11:06, 27.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 94006 \t Episode: 69/1901 \t Total reward episode: -18.0 Total loss: 7.835428857069928 \t Avg_10 loss: 8.87898069525836 \t Avg_10 total_reward: -18.0  \t eps_threshold: 0.4027923104236853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 71/1000 [19:59<7:22:43, 28.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 96170 \t Episode: 70/2163 \t Total reward episode: -16.0 Total loss: 8.22959053365048 \t Avg_10 loss: 8.66090133736725 \t Avg_10 total_reward: -17.8  \t eps_threshold: 0.3945976706150667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 72/1000 [20:27<7:19:08, 28.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 98146 \t Episode: 71/1975 \t Total reward episode: -18.0 Total loss: 7.677425833593588 \t Avg_10 loss: 8.211715397663648 \t Avg_10 total_reward: -17.9  \t eps_threshold: 0.3872682735698659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 73/1000 [20:54<7:15:47, 28.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 100094 \t Episode: 72/1947 \t Total reward episode: -15.0 Total loss: 7.137110526673496 \t Avg_10 loss: 7.980879986914806 \t Avg_10 total_reward: -17.7  \t eps_threshold: 0.3801831210354652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 74/1000 [21:35<8:14:42, 32.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 102667 \t Episode: 73/2572 \t Total reward episode: -17.0 Total loss: 9.666790739749558 \t Avg_10 loss: 8.01572505547083 \t Avg_10 total_reward: -17.8  \t eps_threshold: 0.3710338198469764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 75/1000 [22:09<8:18:56, 32.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 104772 \t Episode: 74/2104 \t Total reward episode: -15.0 Total loss: 7.144697009061929 \t Avg_10 loss: 7.865528670506319 \t Avg_10 total_reward: -17.4  \t eps_threshold: 0.36372178708040503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 76/1000 [22:49<8:53:36, 34.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 107347 \t Episode: 75/2574 \t Total reward episode: -12.0 Total loss: 8.215698395913932 \t Avg_10 loss: 7.940290439646924 \t Avg_10 total_reward: -16.7  \t eps_threshold: 0.35498393373152315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 77/1000 [23:15<8:15:44, 32.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 109064 \t Episode: 76/1716 \t Total reward episode: -20.0 Total loss: 5.552261216565967 \t Avg_10 loss: 7.8629790019418575 \t Avg_10 total_reward: -16.7  \t eps_threshold: 0.34928135631334756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 78/1000 [23:55<8:48:25, 34.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 111609 \t Episode: 77/2544 \t Total reward episode: -13.0 Total loss: 8.403069808031432 \t Avg_10 loss: 7.741715726506664 \t Avg_10 total_reward: -16.3  \t eps_threshold: 0.341006885053444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 79/1000 [24:26<8:35:40, 33.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 113619 \t Episode: 78/2009 \t Total reward episode: -18.0 Total loss: 6.65885100219748 \t Avg_10 loss: 7.652092392250779 \t Avg_10 total_reward: -16.2  \t eps_threshold: 0.334619059372635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 80/1000 [25:07<9:06:45, 35.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 116249 \t Episode: 79/2629 \t Total reward episode: -17.0 Total loss: 9.290723404439632 \t Avg_10 loss: 7.79762184698775 \t Avg_10 total_reward: -16.1  \t eps_threshold: 0.32645243988275296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 81/1000 [25:43<9:09:35, 35.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 118591 \t Episode: 80/2341 \t Total reward episode: -12.0 Total loss: 9.180682466365397 \t Avg_10 loss: 7.892731040259241 \t Avg_10 total_reward: -15.7  \t eps_threshold: 0.31935871549055844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 82/1000 [26:21<9:18:19, 36.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 121018 \t Episode: 81/2426 \t Total reward episode: -14.0 Total loss: 9.392631079594139 \t Avg_10 loss: 8.064251564859296 \t Avg_10 total_reward: -15.3  \t eps_threshold: 0.3121807365750942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 83/1000 [27:07<10:01:19, 39.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 123993 \t Episode: 82/2974 \t Total reward episode: -11.0 Total loss: 10.756944557186216 \t Avg_10 loss: 8.426234967910569 \t Avg_10 total_reward: -14.9  \t eps_threshold: 0.303616386032448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 84/1000 [27:51<10:20:28, 40.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 126777 \t Episode: 83/2783 \t Total reward episode: -12.0 Total loss: 10.819544395373669 \t Avg_10 loss: 8.54151033347298 \t Avg_10 total_reward: -14.4  \t eps_threshold: 0.29582940358630977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 85/1000 [28:22<9:35:37, 37.75s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 128750 \t Episode: 84/1972 \t Total reward episode: -15.0 Total loss: 7.774622654629638 \t Avg_10 loss: 8.60450289802975 \t Avg_10 total_reward: -14.4  \t eps_threshold: 0.29044062456625364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 86/1000 [29:06<10:04:55, 39.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 131552 \t Episode: 85/2801 \t Total reward episode: -12.0 Total loss: 11.471235376026016 \t Avg_10 loss: 8.93005659604096 \t Avg_10 total_reward: -14.4  \t eps_threshold: 0.2829680578249381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 87/1000 [30:05<11:30:16, 45.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 135315 \t Episode: 86/3762 \t Total reward episode: -11.0 Total loss: 15.128707369149197 \t Avg_10 loss: 9.887701211299282 \t Avg_10 total_reward: -13.5  \t eps_threshold: 0.2732564398585754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 88/1000 [30:43<10:58:25, 43.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 137766 \t Episode: 87/2450 \t Total reward episode: -14.0 Total loss: 10.084851688006893 \t Avg_10 loss: 10.055879399296828 \t Avg_10 total_reward: -13.6  \t eps_threshold: 0.2671245774595706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 89/1000 [31:31<11:20:09, 44.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 140803 \t Episode: 88/3036 \t Total reward episode: -13.0 Total loss: 12.571110979828518 \t Avg_10 loss: 10.647105397059931 \t Avg_10 total_reward: -13.1  \t eps_threshold: 0.25973222509072424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 90/1000 [32:13<11:05:28, 43.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 143529 \t Episode: 89/2725 \t Total reward episode: -15.0 Total loss: 12.248569858493283 \t Avg_10 loss: 10.942890042465297 \t Avg_10 total_reward: -12.9  \t eps_threshold: 0.2532853941594879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 91/1000 [32:55<10:56:32, 43.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 146087 \t Episode: 90/2557 \t Total reward episode: -15.0 Total loss: 10.94628197728889 \t Avg_10 loss: 11.119449993557646 \t Avg_10 total_reward: -13.2  \t eps_threshold: 0.24739363069437803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 92/1000 [33:49<11:44:19, 46.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 149497 \t Episode: 91/3409 \t Total reward episode: -12.0 Total loss: 12.87045964866411 \t Avg_10 loss: 11.467232850464644 \t Avg_10 total_reward: -13.0  \t eps_threshold: 0.23977022564379835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 93/1000 [34:53<13:03:12, 51.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 153266 \t Episode: 92/3768 \t Total reward episode: -10.0 Total loss: 13.942032831837423 \t Avg_10 loss: 11.785741677929764 \t Avg_10 total_reward: -12.9  \t eps_threshold: 0.23164123886560117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 94/1000 [35:44<12:57:01, 51.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 156390 \t Episode: 93/3123 \t Total reward episode: -11.0 Total loss: 11.868555997381918 \t Avg_10 loss: 11.890642838130589 \t Avg_10 total_reward: -12.8  \t eps_threshold: 0.2251317738017686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 95/1000 [36:19<11:43:18, 46.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 158528 \t Episode: 94/2137 \t Total reward episode: -14.0 Total loss: 7.656437079946045 \t Avg_10 loss: 11.87882428066223 \t Avg_10 total_reward: -12.7  \t eps_threshold: 0.2207926074525697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 96/1000 [37:02<11:23:09, 45.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 161257 \t Episode: 95/2728 \t Total reward episode: -13.0 Total loss: 11.392161527997814 \t Avg_10 loss: 11.87091689585941 \t Avg_10 total_reward: -12.8  \t eps_threshold: 0.2153870712114701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 97/1000 [37:57<12:07:20, 48.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 164857 \t Episode: 96/3599 \t Total reward episode: -9.0 Total loss: 14.793327708088327 \t Avg_10 loss: 11.837378929753323 \t Avg_10 total_reward: -12.6  \t eps_threshold: 0.20847824171624038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 98/1000 [38:49<12:23:38, 49.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 168357 \t Episode: 97/3499 \t Total reward episode: -9.0 Total loss: 12.507744198403088 \t Avg_10 loss: 12.079668180792941 \t Avg_10 total_reward: -12.1  \t eps_threshold: 0.20199561104790456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 99/1000 [39:46<12:55:11, 51.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 172279 \t Episode: 98/3921 \t Total reward episode: -7.0 Total loss: 13.110258398897713 \t Avg_10 loss: 12.133582922699862 \t Avg_10 total_reward: -11.5  \t eps_threshold: 0.1949959046526135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100/1000 [40:29<12:15:05, 49.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 175197 \t Episode: 99/2917 \t Total reward episode: -12.0 Total loss: 9.326070571230957 \t Avg_10 loss: 11.841332993973628 \t Avg_10 total_reward: -11.2  \t eps_threshold: 0.189963306844974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [41:14<11:57:50, 47.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 178300 \t Episode: 100/3102 \t Total reward episode: -8.0 Total loss: 10.194850099767791 \t Avg_10 loss: 11.766189806221519 \t Avg_10 total_reward: -10.5  \t eps_threshold: 0.1847703311213466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 102/1000 [42:08<12:26:26, 49.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 181972 \t Episode: 101/3671 \t Total reward episode: -8.0 Total loss: 12.826526143006049 \t Avg_10 loss: 11.761796455655713 \t Avg_10 total_reward: -10.1  \t eps_threshold: 0.1788297020062216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 103/1000 [42:55<12:11:55, 48.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 184956 \t Episode: 102/2983 \t Total reward episode: -8.0 Total loss: 11.814400104776723 \t Avg_10 loss: 11.549033182949643 \t Avg_10 total_reward: -9.9  \t eps_threshold: 0.17416023857180396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 104/1000 [43:55<12:58:36, 52.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 188635 \t Episode: 103/3678 \t Total reward episode: -6.0 Total loss: 16.059888170449995 \t Avg_10 loss: 11.96816640025645 \t Avg_10 total_reward: -9.4  \t eps_threshold: 0.16859174392136902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 105/1000 [44:47<12:59:55, 52.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 191982 \t Episode: 104/3346 \t Total reward episode: -14.0 Total loss: 13.610154479218181 \t Avg_10 loss: 12.563538140183663 \t Avg_10 total_reward: -9.4  \t eps_threshold: 0.1637006866835347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 106/1000 [45:35<12:39:43, 50.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 195109 \t Episode: 105/3126 \t Total reward episode: -5.0 Total loss: 11.708995246968698 \t Avg_10 loss: 12.595221512080752 \t Avg_10 total_reward: -8.6  \t eps_threshold: 0.15927669578898276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 107/1000 [46:33<13:08:36, 52.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 198778 \t Episode: 106/3668 \t Total reward episode: -7.0 Total loss: 15.309061890264275 \t Avg_10 loss: 12.646794930298347 \t Avg_10 total_reward: -8.4  \t eps_threshold: 0.1542592418565982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 108/1000 [47:21<12:45:33, 51.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 201803 \t Episode: 107/3024 \t Total reward episode: -8.0 Total loss: 14.314198396983556 \t Avg_10 loss: 12.827440350156394 \t Avg_10 total_reward: -8.3  \t eps_threshold: 0.15025871284820858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 109/1000 [48:12<12:41:03, 51.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 205103 \t Episode: 108/3299 \t Total reward episode: -7.0 Total loss: 14.103031224862207 \t Avg_10 loss: 12.926717632752844 \t Avg_10 total_reward: -8.3  \t eps_threshold: 0.1460303274030771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 110/1000 [48:57<12:12:35, 49.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 208073 \t Episode: 109/2969 \t Total reward episode: -7.0 Total loss: 11.86357144068461 \t Avg_10 loss: 13.180467719698209 \t Avg_10 total_reward: -7.8  \t eps_threshold: 0.1423422654947693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 111/1000 [49:49<12:24:54, 50.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 211506 \t Episode: 110/3432 \t Total reward episode: -3.0 Total loss: 14.700933392450679 \t Avg_10 loss: 13.631076048966497 \t Avg_10 total_reward: -7.3  \t eps_threshold: 0.13821353073746223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 112/1000 [50:31<11:45:55, 47.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 214186 \t Episode: 111/2679 \t Total reward episode: -9.0 Total loss: 11.071597239468247 \t Avg_10 loss: 13.455583158612717 \t Avg_10 total_reward: -7.4  \t eps_threshold: 0.13508748423884315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 113/1000 [51:31<12:38:34, 51.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 218024 \t Episode: 112/3837 \t Total reward episode: -7.0 Total loss: 14.18469425389776 \t Avg_10 loss: 13.692612573524821 \t Avg_10 total_reward: -7.3  \t eps_threshold: 0.13075411584986316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 114/1000 [52:28<13:03:18, 53.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 221773 \t Episode: 113/3748 \t Total reward episode: -8.0 Total loss: 13.037032439082395 \t Avg_10 loss: 13.39032700038806 \t Avg_10 total_reward: -7.5  \t eps_threshold: 0.12667881290898855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 115/1000 [53:19<12:54:41, 52.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 225140 \t Episode: 114/3366 \t Total reward episode: -9.0 Total loss: 13.01062025455758 \t Avg_10 loss: 13.330373577922 \t Avg_10 total_reward: -7.0  \t eps_threshold: 0.12314673351272146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 116/1000 [54:14<13:04:36, 53.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 228718 \t Episode: 115/3577 \t Total reward episode: -8.0 Total loss: 13.36038534383988 \t Avg_10 loss: 13.495512587609118 \t Avg_10 total_reward: -7.3  \t eps_threshold: 0.11952138758456471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 117/1000 [55:00<12:31:04, 51.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 231636 \t Episode: 116/2917 \t Total reward episode: -11.0 Total loss: 10.23750969878165 \t Avg_10 loss: 12.988357368460857 \t Avg_10 total_reward: -7.7  \t eps_threshold: 0.11665931422367341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 118/1000 [56:07<13:43:47, 56.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 235804 \t Episode: 117/4167 \t Total reward episode: -1.0 Total loss: 15.767932737799129 \t Avg_10 loss: 13.133730802542413 \t Avg_10 total_reward: -7.0  \t eps_threshold: 0.11271335894838638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 119/1000 [56:56<13:11:17, 53.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 238814 \t Episode: 118/3009 \t Total reward episode: -10.0 Total loss: 11.430876108875964 \t Avg_10 loss: 12.86651529094379 \t Avg_10 total_reward: -7.3  \t eps_threshold: 0.10996426821508333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 120/1000 [58:05<14:16:30, 58.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 243100 \t Episode: 119/4285 \t Total reward episode: -3.0 Total loss: 16.683462700020755 \t Avg_10 loss: 13.348504416877404 \t Avg_10 total_reward: -6.9  \t eps_threshold: 0.10618986295846658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 121/1000 [59:08<14:36:47, 59.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 246962 \t Episode: 120/3861 \t Total reward episode: -1.0 Total loss: 15.556431382225128 \t Avg_10 loss: 13.434054215854848 \t Avg_10 total_reward: -6.7  \t eps_threshold: 0.10292466720867004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 122/1000 [59:58<13:50:11, 56.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 249941 \t Episode: 121/2978 \t Total reward episode: -9.0 Total loss: 12.570378088159487 \t Avg_10 loss: 13.583932300723973 \t Avg_10 total_reward: -6.7  \t eps_threshold: 0.10049077420153525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 123/1000 [1:00:52<13:36:01, 55.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 253321 \t Episode: 122/3379 \t Total reward episode: -4.0 Total loss: 12.959063049172983 \t Avg_10 loss: 13.461369180251495 \t Avg_10 total_reward: -6.4  \t eps_threshold: 0.09781565030326714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 124/1000 [1:01:43<13:13:47, 54.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 256454 \t Episode: 123/3132 \t Total reward episode: -7.0 Total loss: 11.820698491530493 \t Avg_10 loss: 13.339735785496305 \t Avg_10 total_reward: -6.3  \t eps_threshold: 0.0954154809565032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 125/1000 [1:02:32<12:50:55, 52.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 259436 \t Episode: 124/2981 \t Total reward episode: -4.0 Total loss: 11.555882608518004 \t Avg_10 loss: 13.194262020892348 \t Avg_10 total_reward: -5.8  \t eps_threshold: 0.09319979143134328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 126/1000 [1:03:27<12:59:29, 53.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 262796 \t Episode: 125/3359 \t Total reward episode: -4.0 Total loss: 13.843256699648919 \t Avg_10 loss: 13.24254915647325 \t Avg_10 total_reward: -5.4  \t eps_threshold: 0.0907811393369437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 127/1000 [1:04:31<13:43:44, 56.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 266658 \t Episode: 126/3861 \t Total reward episode: -6.0 Total loss: 14.992378105176613 \t Avg_10 loss: 13.718035997112747 \t Avg_10 total_reward: -4.9  \t eps_threshold: 0.08809968391520673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 128/1000 [1:05:23<13:23:40, 55.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 269876 \t Episode: 127/3217 \t Total reward episode: -4.0 Total loss: 12.167675745789893 \t Avg_10 loss: 13.358010297911823 \t Avg_10 total_reward: -5.2  \t eps_threshold: 0.08594312127921765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 129/1000 [1:06:16<13:13:02, 54.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 273085 \t Episode: 128/3208 \t Total reward episode: -6.0 Total loss: 12.117261633218732 \t Avg_10 loss: 13.426648850346101 \t Avg_10 total_reward: -4.8  \t eps_threshold: 0.08386059928918987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 130/1000 [1:07:14<13:24:44, 55.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 276622 \t Episode: 129/3536 \t Total reward episode: 4.0 Total loss: 12.884938529488863 \t Avg_10 loss: 13.046796433292911 \t Avg_10 total_reward: -4.1  \t eps_threshold: 0.08164132904747887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 131/1000 [1:08:13<13:42:00, 56.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 280359 \t Episode: 130/3736 \t Total reward episode: 2.0 Total loss: 14.287428493931657 \t Avg_10 loss: 12.919896144463564 \t Avg_10 total_reward: -3.8  \t eps_threshold: 0.0793803029770692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 132/1000 [1:09:09<13:37:34, 56.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 283850 \t Episode: 131/3490 \t Total reward episode: 6.0 Total loss: 13.914932147104992 \t Avg_10 loss: 13.054351550358115 \t Avg_10 total_reward: -2.3  \t eps_threshold: 0.07734310282069458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 133/1000 [1:09:46<12:12:20, 50.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 286112 \t Episode: 132/2261 \t Total reward episode: 13.0 Total loss: 8.834886863216525 \t Avg_10 loss: 12.64193393176247 \t Avg_10 total_reward: -0.6  \t eps_threshold: 0.07606056205633986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 134/1000 [1:10:13<10:27:12, 43.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 287768 \t Episode: 133/1655 \t Total reward episode: -13.0 Total loss: 5.90858313877834 \t Avg_10 loss: 12.050722396487254 \t Avg_10 total_reward: -1.2  \t eps_threshold: 0.07513984373726426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 135/1000 [1:11:02<10:48:44, 45.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 290836 \t Episode: 134/3067 \t Total reward episode: 5.0 Total loss: 11.625311018258799 \t Avg_10 loss: 12.057665237461332 \t Avg_10 total_reward: -0.3  \t eps_threshold: 0.07347384049789749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 136/1000 [1:11:43<10:31:29, 43.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 293409 \t Episode: 135/2572 \t Total reward episode: 14.0 Total loss: 10.149313461442944 \t Avg_10 loss: 11.688270913640736 \t Avg_10 total_reward: 1.5  \t eps_threshold: 0.0721155084610881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 137/1000 [1:12:37<11:17:06, 47.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 296742 \t Episode: 136/3332 \t Total reward episode: 7.0 Total loss: 12.173353713180404 \t Avg_10 loss: 11.406368474441114 \t Avg_10 total_reward: 2.8  \t eps_threshold: 0.07040712689184686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 138/1000 [1:13:34<11:57:38, 49.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 300312 \t Episode: 137/3569 \t Total reward episode: 6.0 Total loss: 12.805913610616699 \t Avg_10 loss: 11.470192260923795 \t Avg_10 total_reward: 3.8  \t eps_threshold: 0.06863933529062814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 139/1000 [1:14:18<11:31:43, 48.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 303093 \t Episode: 138/2780 \t Total reward episode: 10.0 Total loss: 9.580606000323314 \t Avg_10 loss: 11.216526697634254 \t Avg_10 total_reward: 5.4  \t eps_threshold: 0.06730531096082792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 140/1000 [1:15:10<11:46:15, 49.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 306330 \t Episode: 139/3236 \t Total reward episode: 10.0 Total loss: 12.294248792342842 \t Avg_10 loss: 11.157457723919652 \t Avg_10 total_reward: 6.0  \t eps_threshold: 0.06579855643168747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 141/1000 [1:15:48<10:58:56, 46.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 308719 \t Episode: 140/2388 \t Total reward episode: 14.0 Total loss: 9.436852177546825 \t Avg_10 loss: 10.672400092281169 \t Avg_10 total_reward: 7.2  \t eps_threshold: 0.06471739481469696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 142/1000 [1:16:23<10:09:56, 42.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 310874 \t Episode: 141/2154 \t Total reward episode: 16.0 Total loss: 8.8629313975689 \t Avg_10 loss: 10.16720001732756 \t Avg_10 total_reward: 8.2  \t eps_threshold: 0.06376404420385376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 143/1000 [1:17:09<10:20:46, 43.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 313649 \t Episode: 142/2774 \t Total reward episode: 10.0 Total loss: 10.372641644498799 \t Avg_10 loss: 10.320975495455787 \t Avg_10 total_reward: 7.9  \t eps_threshold: 0.06256628770984476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 144/1000 [1:17:44<9:45:32, 41.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 315840 \t Episode: 143/2190 \t Total reward episode: 15.0 Total loss: 7.45437229599338 \t Avg_10 loss: 10.47555441117729 \t Avg_10 total_reward: 10.7  \t eps_threshold: 0.061643803068159767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 145/1000 [1:18:25<9:45:15, 41.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 318411 \t Episode: 144/2570 \t Total reward episode: 11.0 Total loss: 9.274875697330572 \t Avg_10 loss: 10.240510879084468 \t Avg_10 total_reward: 11.3  \t eps_threshold: 0.0605867870558013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 146/1000 [1:19:07<9:50:23, 41.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 321069 \t Episode: 145/2657 \t Total reward episode: 12.0 Total loss: 9.139511796063744 \t Avg_10 loss: 10.139530712546549 \t Avg_10 total_reward: 11.1  \t eps_threshold: 0.059522201277284914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 147/1000 [1:19:53<10:05:23, 42.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 323913 \t Episode: 146/2843 \t Total reward episode: 14.0 Total loss: 8.943710011488292 \t Avg_10 loss: 9.816566342377337 \t Avg_10 total_reward: 11.8  \t eps_threshold: 0.05841402286332652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 148/1000 [1:20:41<10:28:42, 44.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 326933 \t Episode: 147/3019 \t Total reward episode: 11.0 Total loss: 9.004873510159086 \t Avg_10 loss: 9.436462332331576 \t Avg_10 total_reward: 12.3  \t eps_threshold: 0.057271261915487454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 149/1000 [1:21:37<11:20:10, 47.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 330479 \t Episode: 148/3545 \t Total reward episode: 3.0 Total loss: 10.335709817067254 \t Avg_10 loss: 9.511972714005969 \t Avg_10 total_reward: 11.6  \t eps_threshold: 0.055972781090543516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 150/1000 [1:22:13<10:28:42, 44.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 332760 \t Episode: 149/2280 \t Total reward episode: 16.0 Total loss: 6.68922434002161 \t Avg_10 loss: 8.951470268773846 \t Avg_10 total_reward: 12.2  \t eps_threshold: 0.05516152945274755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [1:23:04<10:53:51, 46.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 335967 \t Episode: 150/3206 \t Total reward episode: 12.0 Total loss: 9.843529452686198 \t Avg_10 loss: 8.992137996287784 \t Avg_10 total_reward: 12.0  \t eps_threshold: 0.05405178900229858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 152/1000 [1:23:42<10:16:52, 43.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 338316 \t Episode: 151/2348 \t Total reward episode: 15.0 Total loss: 7.338492738257628 \t Avg_10 loss: 8.839694130356657 \t Avg_10 total_reward: 11.9  \t eps_threshold: 0.053261233899035934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 153/1000 [1:24:21<9:56:29, 42.25s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 340763 \t Episode: 152/2446 \t Total reward episode: 12.0 Total loss: 7.165429003303871 \t Avg_10 loss: 8.518972866237164 \t Avg_10 total_reward: 12.1  \t eps_threshold: 0.052457208870914374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 154/1000 [1:24:54<9:20:08, 39.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 342880 \t Episode: 153/2116 \t Total reward episode: 17.0 Total loss: 5.810751798300771 \t Avg_10 loss: 8.354610816467902 \t Avg_10 total_reward: 12.3  \t eps_threshold: 0.051777311861166894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 155/1000 [1:25:31<9:07:17, 38.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 345195 \t Episode: 154/2314 \t Total reward episode: 18.0 Total loss: 6.4626524002233054 \t Avg_10 loss: 8.073388486757176 \t Avg_10 total_reward: 13.0  \t eps_threshold: 0.05105011685022315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 156/1000 [1:26:23<9:59:34, 42.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 348395 \t Episode: 155/3199 \t Total reward episode: 10.0 Total loss: 9.214563100453233 \t Avg_10 loss: 8.080893617196125 \t Avg_10 total_reward: 12.8  \t eps_threshold: 0.050072242543769324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 157/1000 [1:26:55<9:17:00, 39.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 350484 \t Episode: 156/2088 \t Total reward episode: 19.0 Total loss: 5.367858917888952 \t Avg_10 loss: 7.723308507836191 \t Avg_10 total_reward: 13.3  \t eps_threshold: 0.04945054958827686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 158/1000 [1:27:34<9:14:11, 39.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 352960 \t Episode: 157/2475 \t Total reward episode: 17.0 Total loss: 5.96949126815889 \t Avg_10 loss: 7.419770283636171 \t Avg_10 total_reward: 13.9  \t eps_threshold: 0.048730307374531594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 159/1000 [1:28:08<8:48:28, 37.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 355083 \t Episode: 158/2122 \t Total reward episode: 19.0 Total loss: 5.390863345208345 \t Avg_10 loss: 6.925285636450281 \t Avg_10 total_reward: 15.5  \t eps_threshold: 0.04812679193289588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 160/1000 [1:28:46<8:48:43, 37.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 357464 \t Episode: 159/2380 \t Total reward episode: 16.0 Total loss: 5.319397549552377 \t Avg_10 loss: 6.788302957403357 \t Avg_10 total_reward: 15.5  \t eps_threshold: 0.04746500288025563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 161/1000 [1:29:33<9:27:38, 40.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 360413 \t Episode: 160/2948 \t Total reward episode: 8.0 Total loss: 6.073644982127007 \t Avg_10 loss: 6.411314510347438 \t Avg_10 total_reward: 15.1  \t eps_threshold: 0.04666688601847137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 162/1000 [1:30:24<10:08:13, 43.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 363654 \t Episode: 161/3240 \t Total reward episode: 3.0 Total loss: 5.972142425074708 \t Avg_10 loss: 6.274679479029146 \t Avg_10 total_reward: 13.9  \t eps_threshold: 0.045816467710513245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 163/1000 [1:31:04<9:55:57, 42.72s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 366287 \t Episode: 162/2632 \t Total reward episode: 12.0 Total loss: 4.899339543597307 \t Avg_10 loss: 6.04807053305849 \t Avg_10 total_reward: 13.9  \t eps_threshold: 0.04514559096575757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 164/1000 [1:31:47<9:56:20, 42.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 369029 \t Episode: 163/2741 \t Total reward episode: 17.0 Total loss: 5.162867759470828 \t Avg_10 loss: 5.983282129175495 \t Avg_10 total_reward: 13.9  \t eps_threshold: 0.04446546598742197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 165/1000 [1:32:25<9:36:00, 41.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 371552 \t Episode: 164/2522 \t Total reward episode: 13.0 Total loss: 4.82418662722921 \t Avg_10 loss: 5.819435551876086 \t Avg_10 total_reward: 13.4  \t eps_threshold: 0.043855923986370254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 166/1000 [1:33:14<10:03:37, 43.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 374537 \t Episode: 165/2984 \t Total reward episode: 14.0 Total loss: 5.294104329164838 \t Avg_10 loss: 5.427389674747246 \t Avg_10 total_reward: 13.8  \t eps_threshold: 0.0431543477729383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 167/1000 [1:33:47<9:19:01, 40.27s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 376621 \t Episode: 166/2083 \t Total reward episode: 19.0 Total loss: 3.6776665349752875 \t Avg_10 loss: 5.25837043645588 \t Avg_10 total_reward: 13.8  \t eps_threshold: 0.042676804449962184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 168/1000 [1:34:36<9:58:02, 43.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 379734 \t Episode: 167/3112 \t Total reward episode: 7.0 Total loss: 5.137803765450371 \t Avg_10 loss: 5.175201686185028 \t Avg_10 total_reward: 12.8  \t eps_threshold: 0.041981750176383295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 169/1000 [1:35:16<9:42:22, 42.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 382148 \t Episode: 168/2413 \t Total reward episode: 15.0 Total loss: 4.579390551894903 \t Avg_10 loss: 5.094054406853684 \t Avg_10 total_reward: 12.4  \t eps_threshold: 0.041457464317374015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 170/1000 [1:35:49<9:06:13, 39.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 384157 \t Episode: 169/2008 \t Total reward episode: 20.0 Total loss: 3.7905999356735265 \t Avg_10 loss: 4.941174645465798 \t Avg_10 total_reward: 12.8  \t eps_threshold: 0.04103068520957137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 171/1000 [1:36:21<8:32:31, 37.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 386195 \t Episode: 170/2037 \t Total reward episode: 20.0 Total loss: 3.6708855150063755 \t Avg_10 loss: 4.700898698753735 \t Avg_10 total_reward: 14.0  \t eps_threshold: 0.040606417814412536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 172/1000 [1:36:59<8:38:10, 37.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 388647 \t Episode: 171/2451 \t Total reward episode: 15.0 Total loss: 3.7379966258013155 \t Avg_10 loss: 4.477484118826396 \t Avg_10 total_reward: 15.2  \t eps_threshold: 0.04010729273031476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 173/1000 [1:37:39<8:44:18, 38.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 391153 \t Episode: 172/2505 \t Total reward episode: 16.0 Total loss: 3.635572630155366 \t Avg_10 loss: 4.351107427482202 \t Avg_10 total_reward: 15.6  \t eps_threshold: 0.0396096652887158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 174/1000 [1:38:18<8:48:15, 38.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 393659 \t Episode: 173/2505 \t Total reward episode: 14.0 Total loss: 3.6913104386476334 \t Avg_10 loss: 4.203951695399883 \t Avg_10 total_reward: 15.3  \t eps_threshold: 0.03912435343201201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 175/1000 [1:38:50<8:23:57, 36.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 395711 \t Episode: 174/2051 \t Total reward episode: 19.0 Total loss: 3.1439095090463525 \t Avg_10 loss: 4.035923983581597 \t Avg_10 total_reward: 15.9  \t eps_threshold: 0.038735920649634256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 176/1000 [1:39:28<8:25:40, 36.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 397967 \t Episode: 175/2255 \t Total reward episode: 17.0 Total loss: 3.4464777087559924 \t Avg_10 loss: 3.8511613215407126 \t Avg_10 total_reward: 16.2  \t eps_threshold: 0.038317970483934025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 177/1000 [1:40:06<8:29:17, 37.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 400269 \t Episode: 176/2301 \t Total reward episode: 17.0 Total loss: 3.3745634668739513 \t Avg_10 loss: 3.8208510147305788 \t Avg_10 total_reward: 16.0  \t eps_threshold: 0.03790110730708855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 178/1000 [1:40:40<8:19:02, 36.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 402511 \t Episode: 177/2241 \t Total reward episode: 18.0 Total loss: 3.199749950435944 \t Avg_10 loss: 3.627045633229136 \t Avg_10 total_reward: 17.1  \t eps_threshold: 0.03750423009903239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 179/1000 [1:41:14<8:07:08, 35.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 404587 \t Episode: 178/2075 \t Total reward episode: 18.0 Total loss: 2.969001793040661 \t Avg_10 loss: 3.466006757343712 \t Avg_10 total_reward: 17.4  \t eps_threshold: 0.03714458828062278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 180/1000 [1:42:05<9:07:51, 40.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 407821 \t Episode: 179/3233 \t Total reward episode: 7.0 Total loss: 4.996914134855615 \t Avg_10 loss: 3.5866381772619205 \t Avg_10 total_reward: 16.1  \t eps_threshold: 0.03659900197661792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 181/1000 [1:42:40<8:50:18, 38.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 410136 \t Episode: 180/2314 \t Total reward episode: 15.0 Total loss: 3.7200855555420276 \t Avg_10 loss: 3.5915581813154858 \t Avg_10 total_reward: 15.6  \t eps_threshold: 0.036219148845025875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 182/1000 [1:43:26<9:17:03, 40.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 412992 \t Episode: 181/2855 \t Total reward episode: 12.0 Total loss: 4.24042926527909 \t Avg_10 loss: 3.641801445263263 \t Avg_10 total_reward: 15.3  \t eps_threshold: 0.0357624821942736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 183/1000 [1:44:10<9:29:18, 41.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 415766 \t Episode: 182/2773 \t Total reward episode: 12.0 Total loss: 4.16182019826374 \t Avg_10 loss: 3.6944262020741006 \t Avg_10 total_reward: 14.9  \t eps_threshold: 0.03533123992185212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 184/1000 [1:44:45<9:02:13, 39.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 418085 \t Episode: 183/2318 \t Total reward episode: 16.0 Total loss: 3.9463520435383543 \t Avg_10 loss: 3.719930362563173 \t Avg_10 total_reward: 15.1  \t eps_threshold: 0.03497979917310783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 185/1000 [1:45:22<8:48:08, 38.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 420263 \t Episode: 184/2177 \t Total reward episode: 19.0 Total loss: 3.50792494911002 \t Avg_10 loss: 3.7563319065695397 \t Avg_10 total_reward: 15.1  \t eps_threshold: 0.034657066464068034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 186/1000 [1:45:57<8:31:35, 37.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 422546 \t Episode: 185/2282 \t Total reward episode: 17.0 Total loss: 3.5601894379069563 \t Avg_10 loss: 3.767703079484636 \t Avg_10 total_reward: 15.1  \t eps_threshold: 0.03432623643069596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 187/1000 [1:46:35<8:31:52, 37.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 425045 \t Episode: 186/2498 \t Total reward episode: 15.0 Total loss: 3.4618361770844785 \t Avg_10 loss: 3.776430350505689 \t Avg_10 total_reward: 14.9  \t eps_threshold: 0.03397266011882173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 188/1000 [1:47:12<8:26:41, 37.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 427468 \t Episode: 187/2422 \t Total reward episode: 13.0 Total loss: 3.5729524801135994 \t Avg_10 loss: 3.813750603473454 \t Avg_10 total_reward: 14.4  \t eps_threshold: 0.03363817126116255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 189/1000 [1:47:49<8:27:59, 37.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 429972 \t Episode: 188/2503 \t Total reward episode: 14.0 Total loss: 3.129078563157236 \t Avg_10 loss: 3.8297582804851116 \t Avg_10 total_reward: 14.0  \t eps_threshold: 0.03330091156584828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 190/1000 [1:48:28<8:29:45, 37.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 432420 \t Episode: 189/2447 \t Total reward episode: 16.0 Total loss: 3.411744215831277 \t Avg_10 loss: 3.671241288582678 \t Avg_10 total_reward: 14.9  \t eps_threshold: 0.03297925834903401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 191/1000 [1:49:07<8:34:14, 38.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 434953 \t Episode: 190/2532 \t Total reward episode: 15.0 Total loss: 3.3103035770036513 \t Avg_10 loss: 3.6302630907288402 \t Avg_10 total_reward: 14.9  \t eps_threshold: 0.032654622604010045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 192/1000 [1:49:40<8:15:51, 36.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 437172 \t Episode: 191/2218 \t Total reward episode: 17.0 Total loss: 3.0790798932284815 \t Avg_10 loss: 3.5141281535237794 \t Avg_10 total_reward: 15.4  \t eps_threshold: 0.03237690915447443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 193/1000 [1:50:11<7:51:27, 35.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 439184 \t Episode: 192/2011 \t Total reward episode: 20.0 Total loss: 2.661053725561942 \t Avg_10 loss: 3.3640515062536 \t Avg_10 total_reward: 16.2  \t eps_threshold: 0.032130374200607804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 194/1000 [1:50:42<7:35:10, 33.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 441247 \t Episode: 193/2062 \t Total reward episode: 20.0 Total loss: 2.5094346137993853 \t Avg_10 loss: 3.2203597632797027 \t Avg_10 total_reward: 16.6  \t eps_threshold: 0.03188268824594056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 195/1000 [1:51:20<7:47:26, 34.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 443654 \t Episode: 194/2406 \t Total reward episode: 16.0 Total loss: 2.8380403150513303 \t Avg_10 loss: 3.1533712998738337 \t Avg_10 total_reward: 16.3  \t eps_threshold: 0.03160008669353062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 196/1000 [1:51:59<8:07:03, 36.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 446285 \t Episode: 195/2630 \t Total reward episode: 15.0 Total loss: 3.3554123477151734 \t Avg_10 loss: 3.1328935908546556 \t Avg_10 total_reward: 16.1  \t eps_threshold: 0.031298868315865765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 197/1000 [1:52:40<8:22:16, 37.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 448975 \t Episode: 196/2689 \t Total reward episode: 11.0 Total loss: 3.0597956423298456 \t Avg_10 loss: 3.0926895373791923 \t Avg_10 total_reward: 15.7  \t eps_threshold: 0.03099898033479151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 198/1000 [1:53:18<8:26:09, 37.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 451525 \t Episode: 197/2549 \t Total reward episode: 13.0 Total loss: 3.0407920395373367 \t Avg_10 loss: 3.039473493321566 \t Avg_10 total_reward: 15.7  \t eps_threshold: 0.03072205217615886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 199/1000 [1:53:55<8:19:14, 37.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 453801 \t Episode: 198/2275 \t Total reward episode: 17.0 Total loss: 2.9011399862065446 \t Avg_10 loss: 3.0166796356264967 \t Avg_10 total_reward: 16.0  \t eps_threshold: 0.03048077442485949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 200/1000 [1:54:33<8:23:06, 37.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 456220 \t Episode: 199/2418 \t Total reward episode: 14.0 Total loss: 2.7561553564009955 \t Avg_10 loss: 2.9511207496834686 \t Avg_10 total_reward: 15.8  \t eps_threshold: 0.030230286359109897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [1:55:06<8:03:58, 36.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 458349 \t Episode: 200/2128 \t Total reward episode: 17.0 Total loss: 2.5572358153149253 \t Avg_10 loss: 2.875813973514596 \t Avg_10 total_reward: 16.0  \t eps_threshold: 0.030014785706799232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 202/1000 [1:55:43<8:05:32, 36.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 460837 \t Episode: 201/2487 \t Total reward episode: 14.0 Total loss: 3.2818421723204665 \t Avg_10 loss: 2.8960902014237946 \t Avg_10 total_reward: 15.7  \t eps_threshold: 0.029768691939381926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 203/1000 [1:56:15<7:47:42, 35.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 462848 \t Episode: 202/2010 \t Total reward episode: 20.0 Total loss: 2.474577002110891 \t Avg_10 loss: 2.8774425290786896 \t Avg_10 total_reward: 15.7  \t eps_threshold: 0.029574205658376068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 204/1000 [1:56:47<7:32:49, 34.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 464893 \t Episode: 203/2044 \t Total reward episode: 19.0 Total loss: 2.238387793142465 \t Avg_10 loss: 2.850337847012997 \t Avg_10 total_reward: 15.6  \t eps_threshold: 0.029380401553698948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 205/1000 [1:57:17<7:14:50, 32.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 466926 \t Episode: 204/2032 \t Total reward episode: 19.0 Total loss: 2.1446699891530443 \t Avg_10 loss: 2.7810008144231686 \t Avg_10 total_reward: 15.9  \t eps_threshold: 0.0291916234217522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 206/1000 [1:57:50<7:15:43, 32.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 469000 \t Episode: 205/2073 \t Total reward episode: 18.0 Total loss: 2.262387627379212 \t Avg_10 loss: 2.671698342389573 \t Avg_10 total_reward: 16.2  \t eps_threshold: 0.02900295243311977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 207/1000 [1:58:22<7:13:08, 32.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 471097 \t Episode: 206/2096 \t Total reward episode: 19.0 Total loss: 2.0934515055123484 \t Avg_10 loss: 2.5750639287078227 \t Avg_10 total_reward: 17.0  \t eps_threshold: 0.028816126239447612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 208/1000 [1:58:53<7:05:18, 32.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 473108 \t Episode: 207/2010 \t Total reward episode: 20.0 Total loss: 2.0587550392519915 \t Avg_10 loss: 2.4768602286792882 \t Avg_10 total_reward: 17.7  \t eps_threshold: 0.02864060472481411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 209/1000 [1:59:44<8:18:56, 37.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 476387 \t Episode: 208/3278 \t Total reward episode: 9.0 Total loss: 3.435367908750777 \t Avg_10 loss: 2.5302830209337115 \t Avg_10 total_reward: 16.9  \t eps_threshold: 0.028361874058610726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 210/1000 [2:00:25<8:31:39, 38.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 479114 \t Episode: 209/2726 \t Total reward episode: 12.0 Total loss: 2.5978342195230653 \t Avg_10 loss: 2.5144509072459185 \t Avg_10 total_reward: 16.7  \t eps_threshold: 0.02813692684829276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 211/1000 [2:00:59<8:09:22, 37.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 481386 \t Episode: 210/2271 \t Total reward episode: 17.0 Total loss: 2.0773944807006046 \t Avg_10 loss: 2.4664667737844868 \t Avg_10 total_reward: 16.7  \t eps_threshold: 0.02795414018952392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 212/1000 [2:01:31<7:49:24, 35.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 483522 \t Episode: 211/2135 \t Total reward episode: 18.0 Total loss: 2.0028391298255883 \t Avg_10 loss: 2.3385664695349986 \t Avg_10 total_reward: 17.1  \t eps_threshold: 0.027786041440911177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 213/1000 [2:02:08<7:52:13, 36.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 485994 \t Episode: 212/2471 \t Total reward episode: 17.0 Total loss: 2.4760703570282203 \t Avg_10 loss: 2.3387158050267316 \t Avg_10 total_reward: 16.8  \t eps_threshold: 0.027595929955438886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 214/1000 [2:02:40<7:34:58, 34.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 488130 \t Episode: 213/2135 \t Total reward episode: 18.0 Total loss: 2.1386849768459797 \t Avg_10 loss: 2.328745523397083 \t Avg_10 total_reward: 16.7  \t eps_threshold: 0.027435401439516942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 215/1000 [2:03:11<7:22:03, 33.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 490267 \t Episode: 214/2136 \t Total reward episode: 18.0 Total loss: 1.964430187465041 \t Avg_10 loss: 2.310721543228283 \t Avg_10 total_reward: 16.6  \t eps_threshold: 0.027278192669220706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 216/1000 [2:03:42<7:10:52, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 492313 \t Episode: 215/2045 \t Total reward episode: 19.0 Total loss: 2.052939812085242 \t Avg_10 loss: 2.289776761698886 \t Avg_10 total_reward: 16.7  \t eps_threshold: 0.0271307938787032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 217/1000 [2:04:25<7:49:33, 35.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 495169 \t Episode: 216/2855 \t Total reward episode: 15.0 Total loss: 2.9499004618410254 \t Avg_10 loss: 2.3754216573317537 \t Avg_10 total_reward: 16.3  \t eps_threshold: 0.02693001911617361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 218/1000 [2:05:00<7:42:32, 35.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 497491 \t Episode: 217/2321 \t Total reward episode: 16.0 Total loss: 2.274229655318777 \t Avg_10 loss: 2.396969118938432 \t Avg_10 total_reward: 15.9  \t eps_threshold: 0.02677095791945663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 219/1000 [2:05:29<7:20:02, 33.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 499516 \t Episode: 218/2024 \t Total reward episode: 20.0 Total loss: 2.1393026685836958 \t Avg_10 loss: 2.2673625949217238 \t Avg_10 total_reward: 17.0  \t eps_threshold: 0.02663522495606018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 220/1000 [2:06:08<7:36:23, 35.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 502025 \t Episode: 219/2508 \t Total reward episode: 18.0 Total loss: 2.4408419369574403 \t Avg_10 loss: 2.2516633666651615 \t Avg_10 total_reward: 17.6  \t eps_threshold: 0.026470818268331506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 221/1000 [2:06:41<7:28:27, 34.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 504135 \t Episode: 220/2109 \t Total reward episode: 19.0 Total loss: 2.0817002905605477 \t Avg_10 loss: 2.2520939476511557 \t Avg_10 total_reward: 17.8  \t eps_threshold: 0.026335714361516938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 222/1000 [2:07:11<7:12:33, 33.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 506132 \t Episode: 221/1996 \t Total reward episode: 20.0 Total loss: 1.827359052549582 \t Avg_10 loss: 2.234545939923555 \t Avg_10 total_reward: 18.0  \t eps_threshold: 0.026210445122168455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 223/1000 [2:07:42<7:01:46, 32.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 508230 \t Episode: 222/2097 \t Total reward episode: 20.0 Total loss: 2.182404860475799 \t Avg_10 loss: 2.205179390268313 \t Avg_10 total_reward: 18.3  \t eps_threshold: 0.02608150727097437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 224/1000 [2:08:13<6:53:03, 31.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 510230 \t Episode: 223/1999 \t Total reward episode: 20.0 Total loss: 1.7870260375202633 \t Avg_10 loss: 2.1700134963357414 \t Avg_10 total_reward: 18.5  \t eps_threshold: 0.025961085358714466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 225/1000 [2:08:46<6:59:02, 32.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 512393 \t Episode: 224/2162 \t Total reward episode: 16.0 Total loss: 1.9797925459279213 \t Avg_10 loss: 2.1715497321820294 \t Avg_10 total_reward: 18.3  \t eps_threshold: 0.025833531549886633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 226/1000 [2:09:19<7:00:47, 32.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 514491 \t Episode: 225/2097 \t Total reward episode: 18.0 Total loss: 2.0644659659155877 \t Avg_10 loss: 2.172702347565064 \t Avg_10 total_reward: 18.2  \t eps_threshold: 0.02571241897130021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 227/1000 [2:09:52<6:59:56, 32.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 516553 \t Episode: 226/2061 \t Total reward episode: 20.0 Total loss: 1.9293231406918494 \t Avg_10 loss: 2.0706446154501466 \t Avg_10 total_reward: 18.7  \t eps_threshold: 0.02559583500359678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 228/1000 [2:10:27<7:08:58, 33.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 518882 \t Episode: 227/2328 \t Total reward episode: 17.0 Total loss: 2.072780584334396 \t Avg_10 loss: 2.0504997083517083 \t Avg_10 total_reward: 18.8  \t eps_threshold: 0.025467013950444647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 229/1000 [2:11:00<7:06:37, 33.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 521022 \t Episode: 228/2139 \t Total reward episode: 18.0 Total loss: 1.901570769987302 \t Avg_10 loss: 2.026726518492069 \t Avg_10 total_reward: 18.6  \t eps_threshold: 0.025351262806560464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 230/1000 [2:11:33<7:06:17, 33.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 523037 \t Episode: 229/2014 \t Total reward episode: 20.0 Total loss: 1.9201760462819948 \t Avg_10 loss: 1.9746599294245244 \t Avg_10 total_reward: 18.8  \t eps_threshold: 0.025244513967407508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 231/1000 [2:12:05<7:00:49, 32.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 525047 \t Episode: 230/2009 \t Total reward episode: 20.0 Total loss: 1.84203133743722 \t Avg_10 loss: 1.9506930341121915 \t Avg_10 total_reward: 18.9  \t eps_threshold: 0.025140151592130757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 232/1000 [2:12:39<7:06:53, 33.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 527266 \t Episode: 231/2218 \t Total reward episode: 18.0 Total loss: 2.0876661862785113 \t Avg_10 loss: 1.9767237474850845 \t Avg_10 total_reward: 18.7  \t eps_threshold: 0.025027347814850647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 233/1000 [2:13:12<7:04:28, 33.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 529309 \t Episode: 232/2042 \t Total reward episode: 19.0 Total loss: 1.64738600954297 \t Avg_10 loss: 1.9232218623918016 \t Avg_10 total_reward: 18.6  \t eps_threshold: 0.024925681160024905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 234/1000 [2:13:46<7:07:32, 33.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 531493 \t Episode: 233/2183 \t Total reward episode: 16.0 Total loss: 1.7621965280850418 \t Avg_10 loss: 1.9207389114482794 \t Avg_10 total_reward: 18.2  \t eps_threshold: 0.024819270517369485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 235/1000 [2:14:22<7:14:36, 34.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 533770 \t Episode: 234/2276 \t Total reward episode: 18.0 Total loss: 1.9810726591822458 \t Avg_10 loss: 1.9208669227737118 \t Avg_10 total_reward: 18.4  \t eps_threshold: 0.024710775629584174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 236/1000 [2:15:04<7:43:23, 36.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 536448 \t Episode: 235/2677 \t Total reward episode: 16.0 Total loss: 2.308635799061449 \t Avg_10 loss: 1.945283906088298 \t Avg_10 total_reward: 18.2  \t eps_threshold: 0.024586295289338086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 237/1000 [2:15:37<7:31:22, 35.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 538482 \t Episode: 236/2033 \t Total reward episode: 19.0 Total loss: 1.7451338695536833 \t Avg_10 loss: 1.9268649789744814 \t Avg_10 total_reward: 18.1  \t eps_threshold: 0.024493952354421825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 238/1000 [2:16:16<7:43:53, 36.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 540956 \t Episode: 237/2473 \t Total reward episode: 15.0 Total loss: 1.8269550017867004 \t Avg_10 loss: 1.9022824207197118 \t Avg_10 total_reward: 17.9  \t eps_threshold: 0.0243841360026404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 239/1000 [2:16:52<7:39:59, 36.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 543239 \t Episode: 238/2282 \t Total reward episode: 17.0 Total loss: 1.7392420434116502 \t Avg_10 loss: 1.8860495480621466 \t Avg_10 total_reward: 17.8  \t eps_threshold: 0.024285180057832693\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model_name=\"pong_dqn\",\n",
    "    env=env,\n",
    "    n_episodes=1000,\n",
    "    memory=memory,\n",
    "    device=device,\n",
    "    initial_memory=INITIAL_MEMORY,\n",
    "    policy_net=policy_net,\n",
    "    target_net=target_net,\n",
    "    gamma=GAMMA,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_update=TARGET_UPDATE,\n",
    "    eps_end=EPS_END,\n",
    "    eps_start=EPS_START,\n",
    "    eps_decay=EPS_DECAY,\n",
    "    render=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(policy_net, \"dqn_pong_model\")\n",
    "policy_net = torch.load(\"dqn_pong_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
