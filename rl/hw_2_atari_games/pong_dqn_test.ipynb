{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import relu\n",
    "from collections import namedtuple\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import gym\n",
    "import copy\n",
    "import cv2\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from itertools import count\n",
    "from tqdm import tqdm\n",
    "\n",
    "class DQNbn(nn.Module):\n",
    "    def __init__(self, in_channels=4, n_actions=6):\n",
    "        \"\"\"\n",
    "        Initialize Deep Q Network\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): number of input channels\n",
    "            n_actions (int): number of outputs\n",
    "        \"\"\"\n",
    "        super(DQNbn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
    "        self.head = nn.Linear(512, n_actions)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float() / 255\n",
    "        x = relu(self.bn1(self.conv1(x)))\n",
    "        x = relu(self.bn2(self.conv2(x)))\n",
    "        x = relu(self.bn3(self.conv3(x)))\n",
    "        x = relu(self.fc4(x.view(x.size(0), -1)))\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env, stack_frames=True, episodic_life=True, clip_rewards=False, scale=False):\n",
    "    if episodic_life:\n",
    "        env = EpisodicLifeEnv(env)\n",
    "\n",
    "    env = NoopResetEnv(env, noop_max=30)\n",
    "    env = MaxAndSkipEnv(env, skip=4)\n",
    "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "\n",
    "    env = WarpFrame(env)\n",
    "    if stack_frames:\n",
    "        env = FrameStack(env, 4)\n",
    "    if clip_rewards:\n",
    "        env = ClipRewardEnv(env)\n",
    "    return env\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory = self.memory[1:]\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
